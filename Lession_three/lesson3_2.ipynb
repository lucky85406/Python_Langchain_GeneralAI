{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f54fbf35",
   "metadata": {},
   "source": [
    "# Ollama API 參數說明\n",
    "\n",
    "## payload 字典參數詳解\n",
    "\n",
    "### 基本參數\n",
    "- **`model`**: 指定要使用的 AI 模型版本\n",
    "  - 範例: `\"llama3.2:latest\"` - 使用 Llama 3.2 最新版本\n",
    "  - 其他可用模型: `\"gemma2:latest\"`, `\"qwen2:latest\"` 等\n",
    "\n",
    "- **`prompt`**: 輸入給 AI 的問題或指令\n",
    "  - 這是您想要 AI 回答或執行的內容\n",
    "\n",
    "- **`stream`**: 控制回應模式\n",
    "  - `False`: 非串流模式，一次返回完整回應\n",
    "  - `True`: 串流模式，即時返回部分回應\n",
    "\n",
    "### 生成控制參數\n",
    "- **`max_tokens`**: 限制 AI 回應的最大 token 數量\n",
    "  - 約 1 token = 0.75 個英文單詞\n",
    "  - 設定 `100` 表示回應約 75 個英文單詞\n",
    "  - 控制回應長度，避免過長回應\n",
    "\n",
    "- **`format`**: 指定回應格式\n",
    "  - `\"json\"`: 要求 AI 以 JSON 格式回應\n",
    "  - `\"text\"`: 純文字格式（預設）\n",
    "\n",
    "### options 子參數（生成品質控制）\n",
    "\n",
    "#### Temperature（溫度參數）\n",
    "- **範圍**: 0.0 - 1.0\n",
    "- **作用**: 控制回應的創造性和隨機性\n",
    "- **範例值**: `0.7`\n",
    "  - `0.0`: 完全確定性，總是給出相同回應\n",
    "  - `0.3`: 低創造性，回應較為保守\n",
    "  - `0.7`: 平衡創造性和一致性（推薦）\n",
    "  - `1.0`: 高創造性，回應變化很大\n",
    "\n",
    "#### Top-p（核採樣）\n",
    "- **範圍**: 0.0 - 1.0\n",
    "- **作用**: 控制詞彙選擇範圍\n",
    "- **範例值**: `0.9`\n",
    "  - `0.9`: 只考慮累積機率前 90% 的詞彙\n",
    "  - 較高值 = 更多詞彙選擇，回應更多樣\n",
    "  - 較低值 = 更聚焦的詞彙選擇，回應更一致\n",
    "\n",
    "#### Top-k（頂部 K 採樣）\n",
    "- **範圍**: 1 - 1000+\n",
    "- **作用**: 限制每次只考慮機率最高的前 K 個詞彙\n",
    "- **範例值**: `50`\n",
    "  - 防止選擇機率過低的詞彙\n",
    "  - 提高回應品質和一致性\n",
    "  - 較大值 = 更多選擇，較小值 = 更聚焦\n",
    "\n",
    "## 參數調優建議\n",
    "\n",
    "### 創意寫作場景\n",
    "```python\n",
    "\"options\": {\n",
    "    \"temperature\": 0.8,  # 高創造性\n",
    "    \"top_p\": 0.95,       # 更多詞彙選擇\n",
    "    \"top_k\": 100,        # 更多選擇\n",
    "}\n",
    "```\n",
    "\n",
    "### 技術問答場景\n",
    "```python\n",
    "\"options\": {\n",
    "    \"temperature\": 0.3,  # 低創造性\n",
    "    \"top_p\": 0.8,        # 較聚焦\n",
    "    \"top_k\": 30,         # 較少選擇\n",
    "}\n",
    "```\n",
    "\n",
    "### 平衡場景（推薦）\n",
    "```python\n",
    "\"options\": {\n",
    "    \"temperature\": 0.7,  # 平衡\n",
    "    \"top_p\": 0.9,        # 平衡\n",
    "    \"top_k\": 50,         # 平衡\n",
    "}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e360003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💬 AI 回應：\n",
      "{'model': 'gemma3:1b', 'created_at': '2025-09-13T08:00:38.0722077Z', 'response': '{\\n\"解釋：\":\"Python的函式就像小工具，你可以用來做一些特定的事情。你可以把它們想像成一個指令，告訴 Python 執行什麼。 簡單來說，函式會執行一個特定的操作，並會返回結果。\"\\n}', 'done': True, 'done_reason': 'stop', 'context': [105, 2364, 107, 239230, 237105, 74624, 48280, 185411, 26549, 237026, 32651, 236918, 238780, 237522, 237536, 106, 107, 105, 4368, 107, 236782, 107, 236775, 185411, 237184, 12375, 32651, 236918, 238780, 237522, 55326, 237369, 30398, 236900, 71407, 237105, 237967, 237893, 18303, 172612, 25606, 236924, 71407, 91033, 238050, 103146, 237283, 19966, 81582, 236900, 146132, 17856, 236743, 78204, 26549, 236924, 236743, 74624, 94757, 236900, 238780, 237522, 238003, 78204, 19966, 172612, 17553, 236900, 238953, 238003, 29153, 27654, 165220, 107, 236783], 'total_duration': 1670237400, 'load_duration': 124511400, 'prompt_eval_count': 21, 'prompt_eval_duration': 109436000, 'eval_count': 58, 'eval_duration': 1298664500}\n",
      "{\n",
      "\"解釋：\":\"Python的函式就像小工具，你可以用來做一些特定的事情。你可以把它們想像成一個指令，告訴 Python 執行什麼。 簡單來說，函式會執行一個特定的操作，並會返回結果。\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "def chat_with_ollama(prompt: str):\n",
    "    url = \"http://localhost:11434/api/generate\"\n",
    "    payload = {\n",
    "        \"model\": \"gemma3:1b\",\n",
    "        \"prompt\": prompt,\n",
    "        \"stream\": False,\n",
    "        \"options\": { #參考說明1\n",
    "            \"temperature\": 0.7,\n",
    "            \"top_p\": 0.9,\n",
    "            \"top_k\": 50,\n",
    "        },\n",
    "        \"max_tokens\": 1000,\n",
    "        \"format\": \"json\",\n",
    "    }\n",
    "\n",
    "    response = requests.post(url, json=payload)\n",
    "    result = response.json()\n",
    "    print(\"💬 AI 回應：\")\n",
    "    # Print the whole result for debugging\n",
    "    print(result)\n",
    "    # Try to print the 'response' key if it exists, otherwise print possible keys\n",
    "    if \"response\" in result:\n",
    "        print(result[\"response\"])\n",
    "    elif \"message\" in result:\n",
    "        print(result[\"message\"])\n",
    "    elif \"content\" in result:\n",
    "        print(result[\"content\"])\n",
    "    else:\n",
    "        print(\"No expected key found in response. Available keys:\", result.keys())\n",
    "\n",
    "#範例輸入\n",
    "chat_with_ollama(\"請用簡單的方式解釋什麼是Python的函式？\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
