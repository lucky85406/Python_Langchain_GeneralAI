{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f54fbf35",
   "metadata": {},
   "source": [
    "# Ollama API åƒæ•¸èªªæ˜\n",
    "\n",
    "## payload å­—å…¸åƒæ•¸è©³è§£\n",
    "\n",
    "### åŸºæœ¬åƒæ•¸\n",
    "- **`model`**: æŒ‡å®šè¦ä½¿ç”¨çš„ AI æ¨¡å‹ç‰ˆæœ¬\n",
    "  - ç¯„ä¾‹: `\"llama3.2:latest\"` - ä½¿ç”¨ Llama 3.2 æœ€æ–°ç‰ˆæœ¬\n",
    "  - å…¶ä»–å¯ç”¨æ¨¡å‹: `\"gemma2:latest\"`, `\"qwen2:latest\"` ç­‰\n",
    "\n",
    "- **`prompt`**: è¼¸å…¥çµ¦ AI çš„å•é¡Œæˆ–æŒ‡ä»¤\n",
    "  - é€™æ˜¯æ‚¨æƒ³è¦ AI å›ç­”æˆ–åŸ·è¡Œçš„å…§å®¹\n",
    "\n",
    "- **`stream`**: æ§åˆ¶å›æ‡‰æ¨¡å¼\n",
    "  - `False`: éä¸²æµæ¨¡å¼ï¼Œä¸€æ¬¡è¿”å›å®Œæ•´å›æ‡‰\n",
    "  - `True`: ä¸²æµæ¨¡å¼ï¼Œå³æ™‚è¿”å›éƒ¨åˆ†å›æ‡‰\n",
    "\n",
    "### ç”Ÿæˆæ§åˆ¶åƒæ•¸\n",
    "- **`max_tokens`**: é™åˆ¶ AI å›æ‡‰çš„æœ€å¤§ token æ•¸é‡\n",
    "  - ç´„ 1 token = 0.75 å€‹è‹±æ–‡å–®è©\n",
    "  - è¨­å®š `100` è¡¨ç¤ºå›æ‡‰ç´„ 75 å€‹è‹±æ–‡å–®è©\n",
    "  - æ§åˆ¶å›æ‡‰é•·åº¦ï¼Œé¿å…éé•·å›æ‡‰\n",
    "\n",
    "- **`format`**: æŒ‡å®šå›æ‡‰æ ¼å¼\n",
    "  - `\"json\"`: è¦æ±‚ AI ä»¥ JSON æ ¼å¼å›æ‡‰\n",
    "  - `\"text\"`: ç´”æ–‡å­—æ ¼å¼ï¼ˆé è¨­ï¼‰\n",
    "\n",
    "### options å­åƒæ•¸ï¼ˆç”Ÿæˆå“è³ªæ§åˆ¶ï¼‰\n",
    "\n",
    "#### Temperatureï¼ˆæº«åº¦åƒæ•¸ï¼‰\n",
    "- **ç¯„åœ**: 0.0 - 1.0\n",
    "- **ä½œç”¨**: æ§åˆ¶å›æ‡‰çš„å‰µé€ æ€§å’Œéš¨æ©Ÿæ€§\n",
    "- **ç¯„ä¾‹å€¼**: `0.7`\n",
    "  - `0.0`: å®Œå…¨ç¢ºå®šæ€§ï¼Œç¸½æ˜¯çµ¦å‡ºç›¸åŒå›æ‡‰\n",
    "  - `0.3`: ä½å‰µé€ æ€§ï¼Œå›æ‡‰è¼ƒç‚ºä¿å®ˆ\n",
    "  - `0.7`: å¹³è¡¡å‰µé€ æ€§å’Œä¸€è‡´æ€§ï¼ˆæ¨è–¦ï¼‰\n",
    "  - `1.0`: é«˜å‰µé€ æ€§ï¼Œå›æ‡‰è®ŠåŒ–å¾ˆå¤§\n",
    "\n",
    "#### Top-pï¼ˆæ ¸æ¡æ¨£ï¼‰\n",
    "- **ç¯„åœ**: 0.0 - 1.0\n",
    "- **ä½œç”¨**: æ§åˆ¶è©å½™é¸æ“‡ç¯„åœ\n",
    "- **ç¯„ä¾‹å€¼**: `0.9`\n",
    "  - `0.9`: åªè€ƒæ…®ç´¯ç©æ©Ÿç‡å‰ 90% çš„è©å½™\n",
    "  - è¼ƒé«˜å€¼ = æ›´å¤šè©å½™é¸æ“‡ï¼Œå›æ‡‰æ›´å¤šæ¨£\n",
    "  - è¼ƒä½å€¼ = æ›´èšç„¦çš„è©å½™é¸æ“‡ï¼Œå›æ‡‰æ›´ä¸€è‡´\n",
    "\n",
    "#### Top-kï¼ˆé ‚éƒ¨ K æ¡æ¨£ï¼‰\n",
    "- **ç¯„åœ**: 1 - 1000+\n",
    "- **ä½œç”¨**: é™åˆ¶æ¯æ¬¡åªè€ƒæ…®æ©Ÿç‡æœ€é«˜çš„å‰ K å€‹è©å½™\n",
    "- **ç¯„ä¾‹å€¼**: `50`\n",
    "  - é˜²æ­¢é¸æ“‡æ©Ÿç‡éä½çš„è©å½™\n",
    "  - æé«˜å›æ‡‰å“è³ªå’Œä¸€è‡´æ€§\n",
    "  - è¼ƒå¤§å€¼ = æ›´å¤šé¸æ“‡ï¼Œè¼ƒå°å€¼ = æ›´èšç„¦\n",
    "\n",
    "## åƒæ•¸èª¿å„ªå»ºè­°\n",
    "\n",
    "### å‰µæ„å¯«ä½œå ´æ™¯\n",
    "```python\n",
    "\"options\": {\n",
    "    \"temperature\": 0.8,  # é«˜å‰µé€ æ€§\n",
    "    \"top_p\": 0.95,       # æ›´å¤šè©å½™é¸æ“‡\n",
    "    \"top_k\": 100,        # æ›´å¤šé¸æ“‡\n",
    "}\n",
    "```\n",
    "\n",
    "### æŠ€è¡“å•ç­”å ´æ™¯\n",
    "```python\n",
    "\"options\": {\n",
    "    \"temperature\": 0.3,  # ä½å‰µé€ æ€§\n",
    "    \"top_p\": 0.8,        # è¼ƒèšç„¦\n",
    "    \"top_k\": 30,         # è¼ƒå°‘é¸æ“‡\n",
    "}\n",
    "```\n",
    "\n",
    "### å¹³è¡¡å ´æ™¯ï¼ˆæ¨è–¦ï¼‰\n",
    "```python\n",
    "\"options\": {\n",
    "    \"temperature\": 0.7,  # å¹³è¡¡\n",
    "    \"top_p\": 0.9,        # å¹³è¡¡\n",
    "    \"top_k\": 50,         # å¹³è¡¡\n",
    "}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e360003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’¬ AI å›æ‡‰ï¼š\n",
      "{'model': 'gemma3:1b', 'created_at': '2025-09-13T08:00:38.0722077Z', 'response': '{\\n\"è§£é‡‹ï¼š\":\"Pythonçš„å‡½å¼å°±åƒå°å·¥å…·ï¼Œä½ å¯ä»¥ç”¨ä¾†åšä¸€äº›ç‰¹å®šçš„äº‹æƒ…ã€‚ä½ å¯ä»¥æŠŠå®ƒå€‘æƒ³åƒæˆä¸€å€‹æŒ‡ä»¤ï¼Œå‘Šè¨´ Python åŸ·è¡Œä»€éº¼ã€‚ ç°¡å–®ä¾†èªªï¼Œå‡½å¼æœƒåŸ·è¡Œä¸€å€‹ç‰¹å®šçš„æ“ä½œï¼Œä¸¦æœƒè¿”å›çµæœã€‚\"\\n}', 'done': True, 'done_reason': 'stop', 'context': [105, 2364, 107, 239230, 237105, 74624, 48280, 185411, 26549, 237026, 32651, 236918, 238780, 237522, 237536, 106, 107, 105, 4368, 107, 236782, 107, 236775, 185411, 237184, 12375, 32651, 236918, 238780, 237522, 55326, 237369, 30398, 236900, 71407, 237105, 237967, 237893, 18303, 172612, 25606, 236924, 71407, 91033, 238050, 103146, 237283, 19966, 81582, 236900, 146132, 17856, 236743, 78204, 26549, 236924, 236743, 74624, 94757, 236900, 238780, 237522, 238003, 78204, 19966, 172612, 17553, 236900, 238953, 238003, 29153, 27654, 165220, 107, 236783], 'total_duration': 1670237400, 'load_duration': 124511400, 'prompt_eval_count': 21, 'prompt_eval_duration': 109436000, 'eval_count': 58, 'eval_duration': 1298664500}\n",
      "{\n",
      "\"è§£é‡‹ï¼š\":\"Pythonçš„å‡½å¼å°±åƒå°å·¥å…·ï¼Œä½ å¯ä»¥ç”¨ä¾†åšä¸€äº›ç‰¹å®šçš„äº‹æƒ…ã€‚ä½ å¯ä»¥æŠŠå®ƒå€‘æƒ³åƒæˆä¸€å€‹æŒ‡ä»¤ï¼Œå‘Šè¨´ Python åŸ·è¡Œä»€éº¼ã€‚ ç°¡å–®ä¾†èªªï¼Œå‡½å¼æœƒåŸ·è¡Œä¸€å€‹ç‰¹å®šçš„æ“ä½œï¼Œä¸¦æœƒè¿”å›çµæœã€‚\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "def chat_with_ollama(prompt: str):\n",
    "    url = \"http://localhost:11434/api/generate\"\n",
    "    payload = {\n",
    "        \"model\": \"gemma3:1b\",\n",
    "        \"prompt\": prompt,\n",
    "        \"stream\": False,\n",
    "        \"options\": { #åƒè€ƒèªªæ˜1\n",
    "            \"temperature\": 0.7,\n",
    "            \"top_p\": 0.9,\n",
    "            \"top_k\": 50,\n",
    "        },\n",
    "        \"max_tokens\": 1000,\n",
    "        \"format\": \"json\",\n",
    "    }\n",
    "\n",
    "    response = requests.post(url, json=payload)\n",
    "    result = response.json()\n",
    "    print(\"ğŸ’¬ AI å›æ‡‰ï¼š\")\n",
    "    # Print the whole result for debugging\n",
    "    print(result)\n",
    "    # Try to print the 'response' key if it exists, otherwise print possible keys\n",
    "    if \"response\" in result:\n",
    "        print(result[\"response\"])\n",
    "    elif \"message\" in result:\n",
    "        print(result[\"message\"])\n",
    "    elif \"content\" in result:\n",
    "        print(result[\"content\"])\n",
    "    else:\n",
    "        print(\"No expected key found in response. Available keys:\", result.keys())\n",
    "\n",
    "#ç¯„ä¾‹è¼¸å…¥\n",
    "chat_with_ollama(\"è«‹ç”¨ç°¡å–®çš„æ–¹å¼è§£é‡‹ä»€éº¼æ˜¯Pythonçš„å‡½å¼ï¼Ÿ\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
