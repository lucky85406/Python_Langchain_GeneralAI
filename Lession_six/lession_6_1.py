from langchain.prompts import ChatPromptTemplate
from langchain_ollama.llms import OllamaLLM
from langchain.schema.output_parser import StrOutputParser

prompt = ChatPromptTemplate.from_template("""ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„{role}ï¼Œè«‹ç”¨{style}çš„é¢¨æ ¼ä¾†ä»‹ç´¹{topic}ã€‚

è¦æ±‚ï¼š
1. å…§å®¹è¦æº–ç¢ºä¸”æ˜“æ‡‚
2. é•·åº¦æ§åˆ¶åœ¨200å­—ä»¥å…§
3. ä½¿ç”¨ç¹é«”ä¸­æ–‡å›ç­”

è«‹é–‹å§‹ä»‹ç´¹ï¼š""") #å»ºç«‹ChatPromptTemplateå¯¦é«”
model = OllamaLLM(
    model="llama3.2:latest",
    temperature=0.7,
    top_p=0.9)
output_parser = StrOutputParser()

#ä½¿ç”¨LCELèªæ³•å»ºç«‹éˆ

chain = prompt | model | output_parser
# æº–å‚™è¼¸å…¥è³‡æ–™
input_data = {
    "role": "AI å°ˆå®¶",
    "style": "ç°¡æ½”æ˜ç­",
    "topic": "äººå·¥æ™ºæ…§"
}

print("ğŸ“ è¼¸å…¥è³‡æ–™ï¼š")
for key, value in input_data.items():
    print(f"   {key}: {value}")

print("\nğŸ”„ æ­£åœ¨åŸ·è¡ŒåŸºç¤éˆ...")
print("=" * 50)

# åŸ·è¡ŒåŸºç¤éˆ
result = chain.invoke(input_data)

print("=" * 50)
print("âœ… åŸºç¤éˆåŸ·è¡Œå®Œæˆï¼")
print("\nğŸ“‹ å›æ‡‰çµæœï¼š")
print(result)