from langchain_ollama import OllamaLLM
from langchain.prompts import ChatPromptTemplate
import gradio as gr

model_name = "llama3.2:latest"
model = OllamaLLM(model=model_name)

print("=== Ollama æ¨¡å‹è¨­å®šå®Œæˆ ===")
print(f"ä½¿ç”¨æ¨¡å‹ï¼š{model_name}")
print(f"ä½¿ç”¨é¡å‹ï¼š{type(model)}")


# å»ºç«‹å¤šè®Šæ•¸çš„ç¿»è­¯æ¨¡æ¿
complex_template = """
ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„{target_language}ç¿»è­¯å®¶ï¼Œå°ˆç²¾æ–¼{domain}é ˜åŸŸã€‚
è«‹å°‡ä»¥ä¸‹{source_language}æ–‡æœ¬ç¿»è­¯æˆ{target_language}ï¼Œä¸¦ç¢ºä¿ï¼š
1. ä¿æŒåŸæ–‡çš„èªæ°£å’Œé¢¨æ ¼
2. ä½¿ç”¨å°ˆæ¥­è¡“èª
3. ç¬¦åˆ{target_language}çš„èªè¨€ç¿’æ…£
4. ç„¡éœ€åŠ å…¥å…¶ä»–è³‡è¨Š

{source_language}æ–‡æœ¬ï¼š{text}
{target_language}ç¿»è­¯ï¼š
"""

# å»ºç«‹ ChatPromptTemplate
chat_prompt_template = ChatPromptTemplate.from_template(complex_template)

def translate_text(source_language, target_language, domain, text):
    """ä½¿ç”¨ Gradio è¼¸å…¥çš„åƒæ•¸é€²è¡Œç¿»è­¯"""
    if not all([source_language, target_language, domain, text.strip()]):
        return "éŒ¯èª¤ï¼šæ‰€æœ‰æ¬„ä½éƒ½å¿…é ˆå¡«å¯«ï¼"
    
    # ä½¿ç”¨å¤šå€‹è®Šæ•¸æ ¼å¼åŒ– Prompt
    formatted_prompt = chat_prompt_template.format(
        source_language=source_language,
        target_language=target_language, 
        domain=domain,
        text=text
    )
    
    print("=== æ­£åœ¨è™•ç†è«‹æ±‚ ===")
    print(formatted_prompt)
    print(f"{'=' * 50}")
    
    try:
        res = model.invoke(formatted_prompt)
        print(f"æ¨¡å‹å›æ‡‰ï¼š{res}")
        return res
    except Exception as e:
        error_msg = f"å‘¼å«æ¨¡å‹æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}"
        print(error_msg)
        return error_msg

# å»ºç«‹ Gradio ä»‹é¢
iface = gr.Interface(
    fn=translate_text,
    inputs=[
        gr.Dropdown(["è‹±æ–‡", "ç¹é«”ä¸­æ–‡", "æ—¥æ–‡"], label="ä¾†æºèªè¨€", value="è‹±æ–‡"),
        gr.Dropdown(["ç¹é«”ä¸­æ–‡", "è‹±æ–‡", "æ—¥æ–‡"], label="ç›®æ¨™èªè¨€", value="ç¹é«”ä¸­æ–‡"),
        gr.Dropdown(["å•†æ¥­", "ç§‘æŠ€", "ç”Ÿæ´»", "å­¸è¡“"], label="å°ˆæ¥­é ˜åŸŸ", value="å•†æ¥­"),
        gr.Textbox(lines=5, label="è¦ç¿»è­¯çš„æ–‡æœ¬", placeholder="è«‹åœ¨æ­¤è¼¸å…¥è¦ç¿»è­¯çš„å…§å®¹...")
    ],
    outputs=gr.Textbox(label="ç¿»è­¯çµæœ"),
    title="å°ˆæ¥­é ˜åŸŸç¿»è­¯å™¨",
    description="é€™æ˜¯ä¸€å€‹ä½¿ç”¨ LangChain å’Œ Ollama (Llama 3.2) æ‰“é€ çš„å°ˆæ¥­ç¿»è­¯å·¥å…·ã€‚è«‹é¸æ“‡èªè¨€ã€å°ˆæ¥­é ˜åŸŸï¼Œä¸¦è¼¸å…¥æ‚¨æƒ³ç¿»è­¯çš„æ–‡æœ¬ã€‚",
    examples=[
        ["è‹±æ–‡", "ç¹é«”ä¸­æ–‡", "å•†æ¥­", "The quarterly revenue increased by 15% compared to last year."],
        ["è‹±æ–‡", "ç¹é«”ä¸­æ–‡", "ç§‘æŠ€", "The new algorithm improves data processing efficiency by optimizing memory allocation."],
        ["ç¹é«”ä¸­æ–‡", "è‹±æ–‡", "ç”Ÿæ´»", "ä»Šå¤©å¤©æ°£çœŸå¥½ï¼Œæˆ‘å€‘å»å…¬åœ’æ•£æ­¥å§ï¼"]
    ]
)

if __name__ == "__main__":
    print("ğŸš€ å•Ÿå‹• Gradio å°ˆæ¥­ç¿»è­¯å™¨ä»‹é¢...")
    iface.launch()